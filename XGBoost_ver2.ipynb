{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost_ver2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OXso0wndd7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d707f9b0-94b6-4e83-af92-4e1d6b4d89ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuOOp-PZd37P",
        "outputId": "cef0b178-f0ba-44cd-9bcd-51f6853c0172"
      },
      "source": [
        "cd /content/drive/My Drive/psat_summer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/psat_summer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVgdBDc4eAEZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import pickle\n",
        "import joblib"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3CdRPczeGCK"
      },
      "source": [
        "train = pd.read_csv(\"train_mwmote.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig-ras-WgOCs"
      },
      "source": [
        "y = train['target']\n",
        "x = train.drop('target', axis = 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmxhdIj9xEtL"
      },
      "source": [
        "시도 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hO_1f6JsaEA",
        "outputId": "af8d626f-7478-42b1-da45-79d92f04b602"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.01,\n",
        "              'n_estimators': 400, \n",
        "              'max_depth': 4,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.218319\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.203037\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-error:0.20254\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.80      0.78      0.79      5020\n",
            "     class 1       0.79      0.81      0.80      5057\n",
            "\n",
            "    accuracy                           0.80     10077\n",
            "   macro avg       0.80      0.80      0.80     10077\n",
            "weighted avg       0.80      0.80      0.80     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.217525\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.20135\n",
            "[200]\tvalidation_0-error:0.192518\n",
            "[300]\tvalidation_0-error:0.185869\n",
            "[399]\tvalidation_0-error:0.176938\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.84      0.80      0.82      5053\n",
            "     class 1       0.81      0.85      0.83      5024\n",
            "\n",
            "    accuracy                           0.82     10077\n",
            "   macro avg       0.82      0.82      0.82     10077\n",
            "weighted avg       0.82      0.82      0.82     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.214669\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.202759\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-error:0.201072\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.83      0.76      0.79      5048\n",
            "     class 1       0.78      0.84      0.81      5028\n",
            "\n",
            "    accuracy                           0.80     10076\n",
            "   macro avg       0.80      0.80      0.80     10076\n",
            "weighted avg       0.80      0.80      0.80     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.216753\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.205637\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-error:0.202461\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.81      0.78      0.79      4992\n",
            "     class 1       0.79      0.82      0.80      5084\n",
            "\n",
            "    accuracy                           0.80     10076\n",
            "   macro avg       0.80      0.80      0.80     10076\n",
            "weighted avg       0.80      0.80      0.80     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.220127\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.200179\n",
            "[200]\tvalidation_0-error:0.19343\n",
            "[300]\tvalidation_0-error:0.185689\n",
            "[399]\tvalidation_0-error:0.177749\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.84      0.80      0.82      5078\n",
            "     class 1       0.81      0.84      0.82      4998\n",
            "\n",
            "    accuracy                           0.82     10076\n",
            "   macro avg       0.82      0.82      0.82     10076\n",
            "weighted avg       0.82      0.82      0.82     10076\n",
            "\n",
            "F1 score : 0.812498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-GeU79HxG4M"
      },
      "source": [
        "시도 2 - learning rate 조정 (0.01 -> **0.05**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK4MA5_RxMoS",
        "outputId": "8f8760d0-323e-4666-bc0d-b01b0332c77b"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.05,\n",
        "              'n_estimators': 400, \n",
        "              'max_depth': 4,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.218319\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.172075\n",
            "[200]\tvalidation_0-error:0.141014\n",
            "[300]\tvalidation_0-error:0.119182\n",
            "[399]\tvalidation_0-error:0.107572\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.90      0.88      0.89      5020\n",
            "     class 1       0.88      0.91      0.89      5057\n",
            "\n",
            "    accuracy                           0.89     10077\n",
            "   macro avg       0.89      0.89      0.89     10077\n",
            "weighted avg       0.89      0.89      0.89     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.217525\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.169197\n",
            "[200]\tvalidation_0-error:0.133075\n",
            "[300]\tvalidation_0-error:0.112732\n",
            "[399]\tvalidation_0-error:0.100824\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.92      0.88      0.90      5053\n",
            "     class 1       0.88      0.92      0.90      5024\n",
            "\n",
            "    accuracy                           0.90     10077\n",
            "   macro avg       0.90      0.90      0.90     10077\n",
            "weighted avg       0.90      0.90      0.90     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.214669\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.167527\n",
            "[200]\tvalidation_0-error:0.133287\n",
            "[300]\tvalidation_0-error:0.112743\n",
            "[399]\tvalidation_0-error:0.099841\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.91      0.88      0.90      5048\n",
            "     class 1       0.89      0.92      0.90      5028\n",
            "\n",
            "    accuracy                           0.90     10076\n",
            "   macro avg       0.90      0.90      0.90     10076\n",
            "weighted avg       0.90      0.90      0.90     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.216753\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.170206\n",
            "[200]\tvalidation_0-error:0.137654\n",
            "[300]\tvalidation_0-error:0.118202\n",
            "[399]\tvalidation_0-error:0.1052\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.91      0.88      0.89      4992\n",
            "     class 1       0.88      0.91      0.90      5084\n",
            "\n",
            "    accuracy                           0.90     10076\n",
            "   macro avg       0.90      0.89      0.90     10076\n",
            "weighted avg       0.90      0.90      0.90     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.220127\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.16842\n",
            "[200]\tvalidation_0-error:0.134974\n",
            "[300]\tvalidation_0-error:0.118003\n",
            "[399]\tvalidation_0-error:0.1053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.91      0.88      0.89      5078\n",
            "     class 1       0.88      0.91      0.90      4998\n",
            "\n",
            "    accuracy                           0.90     10076\n",
            "   macro avg       0.90      0.90      0.90     10076\n",
            "weighted avg       0.90      0.90      0.90     10076\n",
            "\n",
            "F1 score : 0.898276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjoH2pr6yF0d"
      },
      "source": [
        "시도 3. learning rate 조정 (0.05 -> **0.1**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "xzPHZKsPyFSU",
        "outputId": "674e4c38-26b5-49a3-e3a9-66618a98c29c"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.1,\n",
        "              'n_estimators': 400, \n",
        "              'max_depth': 4,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.218319\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.143694\n",
            "[200]\tvalidation_0-error:0.110053\n",
            "[300]\tvalidation_0-error:0.095862\n",
            "[399]\tvalidation_0-error:0.082763\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.93      0.91      0.92      5020\n",
            "     class 1       0.91      0.93      0.92      5057\n",
            "\n",
            "    accuracy                           0.92     10077\n",
            "   macro avg       0.92      0.92      0.92     10077\n",
            "weighted avg       0.92      0.92      0.92     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.217525\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-45e547a4cfbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL9ihTZB1lEQ"
      },
      "source": [
        "시도 4. learning rate 조정(0.1 -> 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRrUyyoQ1kLW",
        "outputId": "200f6731-9860-48ea-ab5c-e68150035736"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.3,\n",
        "              'n_estimators': 400, \n",
        "              'max_depth': 4,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.218319\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.099831\n",
            "[200]\tvalidation_0-error:0.075816\n",
            "[300]\tvalidation_0-error:0.063908\n",
            "[399]\tvalidation_0-error:0.057358\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.95      0.93      0.94      5020\n",
            "     class 1       0.93      0.95      0.94      5057\n",
            "\n",
            "    accuracy                           0.94     10077\n",
            "   macro avg       0.94      0.94      0.94     10077\n",
            "weighted avg       0.94      0.94      0.94     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.217525\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.095961\n",
            "[200]\tvalidation_0-error:0.076412\n",
            "[300]\tvalidation_0-error:0.066687\n",
            "[399]\tvalidation_0-error:0.059145\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.92      0.94      5053\n",
            "     class 1       0.93      0.96      0.94      5024\n",
            "\n",
            "    accuracy                           0.94     10077\n",
            "   macro avg       0.94      0.94      0.94     10077\n",
            "weighted avg       0.94      0.94      0.94     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.214669\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.095772\n",
            "[200]\tvalidation_0-error:0.075129\n",
            "[300]\tvalidation_0-error:0.065403\n",
            "[399]\tvalidation_0-error:0.058456\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.95      0.93      0.94      5048\n",
            "     class 1       0.93      0.95      0.94      5028\n",
            "\n",
            "    accuracy                           0.94     10076\n",
            "   macro avg       0.94      0.94      0.94     10076\n",
            "weighted avg       0.94      0.94      0.94     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.216753\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.093787\n",
            "[200]\tvalidation_0-error:0.076518\n",
            "[300]\tvalidation_0-error:0.063914\n",
            "[399]\tvalidation_0-error:0.057265\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.95      0.93      0.94      4992\n",
            "     class 1       0.93      0.96      0.94      5084\n",
            "\n",
            "    accuracy                           0.94     10076\n",
            "   macro avg       0.94      0.94      0.94     10076\n",
            "weighted avg       0.94      0.94      0.94     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.220127\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.099047\n",
            "[200]\tvalidation_0-error:0.07761\n",
            "[300]\tvalidation_0-error:0.066098\n",
            "[399]\tvalidation_0-error:0.056967\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.93      0.94      5078\n",
            "     class 1       0.93      0.96      0.94      4998\n",
            "\n",
            "    accuracy                           0.94     10076\n",
            "   macro avg       0.94      0.94      0.94     10076\n",
            "weighted avg       0.94      0.94      0.94     10076\n",
            "\n",
            "F1 score : 0.943054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTdfYKyO2EiN"
      },
      "source": [
        "시도 5. learning rate 조정 (0.3 -> **0.5**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfcvFwbZ2T5K",
        "outputId": "72b1768d-9888-4bc7-c3d0-a49548e2bbbf"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.5,\n",
        "              'n_estimators': 400, \n",
        "              'max_depth': 4,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.218319\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.091793\n",
            "[200]\tvalidation_0-error:0.069366\n",
            "[300]\tvalidation_0-error:0.058648\n",
            "[399]\tvalidation_0-error:0.052397\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.93      0.95      5020\n",
            "     class 1       0.94      0.96      0.95      5057\n",
            "\n",
            "    accuracy                           0.95     10077\n",
            "   macro avg       0.95      0.95      0.95     10077\n",
            "weighted avg       0.95      0.95      0.95     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.217525\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.089114\n",
            "[200]\tvalidation_0-error:0.065496\n",
            "[300]\tvalidation_0-error:0.058748\n",
            "[399]\tvalidation_0-error:0.053389\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.93      0.95      5053\n",
            "     class 1       0.93      0.97      0.95      5024\n",
            "\n",
            "    accuracy                           0.95     10077\n",
            "   macro avg       0.95      0.95      0.95     10077\n",
            "weighted avg       0.95      0.95      0.95     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.214669\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.089619\n",
            "[200]\tvalidation_0-error:0.069869\n",
            "[300]\tvalidation_0-error:0.05925\n",
            "[399]\tvalidation_0-error:0.052997\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.93      0.95      5048\n",
            "     class 1       0.93      0.96      0.95      5028\n",
            "\n",
            "    accuracy                           0.95     10076\n",
            "   macro avg       0.95      0.95      0.95     10076\n",
            "weighted avg       0.95      0.95      0.95     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.216753\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.088229\n",
            "[200]\tvalidation_0-error:0.070464\n",
            "[300]\tvalidation_0-error:0.059051\n",
            "[399]\tvalidation_0-error:0.052997\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.93      0.95      4992\n",
            "     class 1       0.93      0.96      0.95      5084\n",
            "\n",
            "    accuracy                           0.95     10076\n",
            "   macro avg       0.95      0.95      0.95     10076\n",
            "weighted avg       0.95      0.95      0.95     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.220127\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.091207\n",
            "[200]\tvalidation_0-error:0.071556\n",
            "[300]\tvalidation_0-error:0.061235\n",
            "[399]\tvalidation_0-error:0.054684\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      0.93      0.94      5078\n",
            "     class 1       0.93      0.96      0.95      4998\n",
            "\n",
            "    accuracy                           0.95     10076\n",
            "   macro avg       0.95      0.95      0.95     10076\n",
            "weighted avg       0.95      0.95      0.95     10076\n",
            "\n",
            "F1 score : 0.948149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5EGvVpE2X9_"
      },
      "source": [
        "n_estimators 조정 (400 -> 800) \\\n",
        "learning_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_UN7v573r4J",
        "outputId": "f5f2e715-7a62-4361-9469-2a59373de92a"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.5,\n",
        "              'n_estimators': 800, \n",
        "              'max_depth': 4,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.218319\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.091793\n",
            "[200]\tvalidation_0-error:0.069366\n",
            "[300]\tvalidation_0-error:0.058648\n",
            "[400]\tvalidation_0-error:0.052793\n",
            "[500]\tvalidation_0-error:0.048129\n",
            "[600]\tvalidation_0-error:0.045748\n",
            "[700]\tvalidation_0-error:0.043763\n",
            "[799]\tvalidation_0-error:0.04287\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.96      5020\n",
            "     class 1       0.95      0.97      0.96      5057\n",
            "\n",
            "    accuracy                           0.96     10077\n",
            "   macro avg       0.96      0.96      0.96     10077\n",
            "weighted avg       0.96      0.96      0.96     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.217525\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.089114\n",
            "[200]\tvalidation_0-error:0.065496\n",
            "[300]\tvalidation_0-error:0.058748\n",
            "[400]\tvalidation_0-error:0.05319\n",
            "[500]\tvalidation_0-error:0.048923\n",
            "Stopping. Best iteration:\n",
            "[477]\tvalidation_0-error:0.047336\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.93      0.95      5053\n",
            "     class 1       0.93      0.97      0.95      5024\n",
            "\n",
            "    accuracy                           0.95     10077\n",
            "   macro avg       0.95      0.95      0.95     10077\n",
            "weighted avg       0.95      0.95      0.95     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.214669\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.089619\n",
            "[200]\tvalidation_0-error:0.069869\n",
            "[300]\tvalidation_0-error:0.05925\n",
            "[400]\tvalidation_0-error:0.052898\n",
            "[500]\tvalidation_0-error:0.049524\n",
            "[600]\tvalidation_0-error:0.046645\n",
            "[700]\tvalidation_0-error:0.044164\n",
            "[799]\tvalidation_0-error:0.042477\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.96      5048\n",
            "     class 1       0.94      0.97      0.96      5028\n",
            "\n",
            "    accuracy                           0.96     10076\n",
            "   macro avg       0.96      0.96      0.96     10076\n",
            "weighted avg       0.96      0.96      0.96     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.216753\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.088229\n",
            "[200]\tvalidation_0-error:0.070464\n",
            "[300]\tvalidation_0-error:0.059051\n",
            "[400]\tvalidation_0-error:0.053394\n",
            "[500]\tvalidation_0-error:0.049821\n",
            "[600]\tvalidation_0-error:0.047439\n",
            "[700]\tvalidation_0-error:0.045157\n",
            "[799]\tvalidation_0-error:0.043271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.96      4992\n",
            "     class 1       0.94      0.97      0.96      5084\n",
            "\n",
            "    accuracy                           0.96     10076\n",
            "   macro avg       0.96      0.96      0.96     10076\n",
            "weighted avg       0.96      0.96      0.96     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.220127\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.091207\n",
            "[200]\tvalidation_0-error:0.071556\n",
            "[300]\tvalidation_0-error:0.061235\n",
            "[400]\tvalidation_0-error:0.054486\n",
            "[500]\tvalidation_0-error:0.052104\n",
            "[600]\tvalidation_0-error:0.05002\n",
            "[700]\tvalidation_0-error:0.047539\n",
            "[799]\tvalidation_0-error:0.045951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.95      5078\n",
            "     class 1       0.94      0.97      0.95      4998\n",
            "\n",
            "    accuracy                           0.95     10076\n",
            "   macro avg       0.95      0.95      0.95     10076\n",
            "weighted avg       0.96      0.95      0.95     10076\n",
            "\n",
            "F1 score : 0.956557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkUMDTw6-nyR"
      },
      "source": [
        "max_depth 조정 (4 -> 5) \\\n",
        "n_estimators = 800 \\\n",
        "learning_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "7OnT6774-nyX",
        "outputId": "31cc8b17-eb15-4dcd-a00b-ec42e18336d2"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.5,\n",
        "              'n_estimators': 800, \n",
        "              'max_depth': 5,  \n",
        "              'min_child_weight' : 2.5,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-5fdb75e15054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsWK17rVKN_b"
      },
      "source": [
        "min_child_weight 조정 (2.5 -> 3) \\\n",
        "max_depth = 5 \\\n",
        "n_estimators = 800 \\\n",
        "learning_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW9dq12cKN_g",
        "outputId": "b45a05f0-6b2d-4f3f-d92e-9056aede7736"
      },
      "source": [
        "CM = []\n",
        "f1_scores = []\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x)) :\n",
        "    train_X, train_y = x.iloc[trn_idx], y.iloc[trn_idx]\n",
        "    valid_X, valid_y = x.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "    params = {'learning_rate': 0.5,\n",
        "              'n_estimators': 800, \n",
        "              'max_depth': 5,  \n",
        "              'min_child_weight' : 3,\n",
        "              'subsample' : 0.7,\n",
        "              'colsample_bytree' : 0.7,\n",
        "              'reg_lambda' : 3,\n",
        "              'objective': 'binary:logistic',  \n",
        "              'random_state': 0}\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(train_X, train_y, eval_set=[(valid_X, valid_y)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "    y_pred = model.predict(valid_X)\n",
        "\n",
        "    CM.append(confusion_matrix(valid_y, y_pred))\n",
        "    f1_scores.append(f1_score(valid_y, y_pred))\n",
        "    print(classification_report(valid_y, y_pred, target_names=['class 0', 'class 1']))\n",
        "\n",
        "CM = sum(CM)\n",
        "f1_scores = np.mean(f1_scores)\n",
        "print(\"F1 score : %f\" % f1_scores)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.214846\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.074328\n",
            "[200]\tvalidation_0-error:0.055969\n",
            "[300]\tvalidation_0-error:0.048427\n",
            "[400]\tvalidation_0-error:0.046343\n",
            "[500]\tvalidation_0-error:0.043565\n",
            "[600]\tvalidation_0-error:0.042572\n",
            "[700]\tvalidation_0-error:0.041778\n",
            "Stopping. Best iteration:\n",
            "[667]\tvalidation_0-error:0.040389\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.95      0.96      5020\n",
            "     class 1       0.95      0.97      0.96      5057\n",
            "\n",
            "    accuracy                           0.96     10077\n",
            "   macro avg       0.96      0.96      0.96     10077\n",
            "weighted avg       0.96      0.96      0.96     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.211869\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.072343\n",
            "[200]\tvalidation_0-error:0.053389\n",
            "[300]\tvalidation_0-error:0.047236\n",
            "[400]\tvalidation_0-error:0.043664\n",
            "[500]\tvalidation_0-error:0.042671\n",
            "[600]\tvalidation_0-error:0.04158\n",
            "[700]\tvalidation_0-error:0.04029\n",
            "Stopping. Best iteration:\n",
            "[670]\tvalidation_0-error:0.039694\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.94      0.96      5053\n",
            "     class 1       0.94      0.98      0.96      5024\n",
            "\n",
            "    accuracy                           0.96     10077\n",
            "   macro avg       0.96      0.96      0.96     10077\n",
            "weighted avg       0.96      0.96      0.96     10077\n",
            "\n",
            "[0]\tvalidation_0-error:0.212783\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.076221\n",
            "[200]\tvalidation_0-error:0.056074\n",
            "[300]\tvalidation_0-error:0.046645\n",
            "[400]\tvalidation_0-error:0.042477\n",
            "[500]\tvalidation_0-error:0.040195\n",
            "[600]\tvalidation_0-error:0.03811\n",
            "Stopping. Best iteration:\n",
            "[596]\tvalidation_0-error:0.037416\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.95      0.96      5048\n",
            "     class 1       0.95      0.97      0.96      5028\n",
            "\n",
            "    accuracy                           0.96     10076\n",
            "   macro avg       0.96      0.96      0.96     10076\n",
            "weighted avg       0.96      0.96      0.96     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.214768\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.072648\n",
            "[200]\tvalidation_0-error:0.052699\n",
            "[300]\tvalidation_0-error:0.047539\n",
            "[400]\tvalidation_0-error:0.044462\n",
            "[500]\tvalidation_0-error:0.042973\n",
            "[600]\tvalidation_0-error:0.041683\n",
            "[700]\tvalidation_0-error:0.040492\n",
            "[799]\tvalidation_0-error:0.039599\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.94      0.96      4992\n",
            "     class 1       0.94      0.98      0.96      5084\n",
            "\n",
            "    accuracy                           0.96     10076\n",
            "   macro avg       0.96      0.96      0.96     10076\n",
            "weighted avg       0.96      0.96      0.96     10076\n",
            "\n",
            "[0]\tvalidation_0-error:0.215066\n",
            "Will train until validation_0-error hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.07503\n",
            "[200]\tvalidation_0-error:0.055181\n",
            "[300]\tvalidation_0-error:0.050715\n",
            "[400]\tvalidation_0-error:0.044958\n",
            "[500]\tvalidation_0-error:0.044561\n",
            "Stopping. Best iteration:\n",
            "[481]\tvalidation_0-error:0.04347\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.97      0.94      0.96      5078\n",
            "     class 1       0.94      0.97      0.96      4998\n",
            "\n",
            "    accuracy                           0.96     10076\n",
            "   macro avg       0.96      0.96      0.96     10076\n",
            "weighted avg       0.96      0.96      0.96     10076\n",
            "\n",
            "F1 score : 0.960519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgFyCwIOwimV"
      },
      "source": [
        "모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7oMp1qvAJDL"
      },
      "source": [
        "model = XGBClassifier(learning_rate=0.5, n_estimators=800, max_depth=5, min_child_weight=3, subsample=0.7, colsample_bytree=0.7, reg_lambda=3, objective='binary:logistic', random_state=0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_AJdP6eAXpH",
        "outputId": "c3fbd047-06c9-4488-c18f-04e2e3cf563b"
      },
      "source": [
        "model.fit(x, y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
              "              learning_rate=0.5, max_delta_step=0, max_depth=5,\n",
              "              min_child_weight=3, missing=None, n_estimators=800, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=3, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=0.7, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azzq-9oYAS2x"
      },
      "source": [
        "test = pd.read_csv(\"test_pca.csv\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDq2OKsXAdDE",
        "outputId": "c7115245-38e4-4258-e389-df9976bbc1b5"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7-ePOVqALgt"
      },
      "source": [
        "prediction = model.predict(test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoUs_ZBdAhId"
      },
      "source": [
        "submission = pd.DataFrame(columns = ['id', 'target'])\n",
        "submission['id'] = range(1,2001)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SomWYDfJAhoS"
      },
      "source": [
        "submission['target'] = prediction"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz_psUJnAi5U",
        "outputId": "230c514c-b3b8-4b06-d0cb-ff3a40f0102d"
      },
      "source": [
        "submission['target'].value_counts()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1843\n",
              "1     157\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnhYGsWEAkh4"
      },
      "source": [
        "submission.to_csv(\"xgboost_ver2.csv\", header = True, index = False)"
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}